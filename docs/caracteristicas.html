<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 3 Características dos métodos de interpretabilidade | Interprete o seu modelo caixa-preta!</title>
  <meta name="description" content="Capítulo 3 Características dos métodos de interpretabilidade | Interprete o seu modelo caixa-preta!" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 3 Características dos métodos de interpretabilidade | Interprete o seu modelo caixa-preta!" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 3 Características dos métodos de interpretabilidade | Interprete o seu modelo caixa-preta!" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="interpglobal.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Material sobre técnicas de interpretabilidade</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Sobre esse material</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#autores"><i class="fa fa-check"></i><b>1.1</b> Autores</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#alinhando-expectativas"><i class="fa fa-check"></i><b>1.2</b> Alinhando Expectativas</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introdução</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#algoritmo-de-contratação-sexista"><i class="fa fa-check"></i><b>2.1</b> Algoritmo de Contratação sexista</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#algoritmo-de-classificação-de-imagens"><i class="fa fa-check"></i><b>2.2</b> Algoritmo de classificação de imagens</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="caracteristicas.html"><a href="caracteristicas.html"><i class="fa fa-check"></i><b>3</b> Características dos métodos de interpretabilidade</a></li>
<li class="chapter" data-level="4" data-path="interpglobal.html"><a href="interpglobal.html"><i class="fa fa-check"></i><b>4</b> Interpretabilidade Global</a><ul>
<li class="chapter" data-level="4.1" data-path="interpglobal.html"><a href="interpglobal.html#gráfico-de-dependência-parcial-partial-dependence-plot---pdp"><i class="fa fa-check"></i><b>4.1</b> Gráfico de Dependência Parcial (<em>Partial Dependence Plot</em>) - PDP</a><ul>
<li class="chapter" data-level="4.1.1" data-path="interpglobal.html"><a href="interpglobal.html#vantagens-e-desvantagens"><i class="fa fa-check"></i><b>4.1.1</b> Vantagens e Desvantagens</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="interpglobal.html"><a href="interpglobal.html#esperança-condicional-individual-individual-conditional-expectation---ice"><i class="fa fa-check"></i><b>4.2</b> Esperança Condicional Individual (<em>Individual Conditional Expectation</em>) - ICE</a><ul>
<li class="chapter" data-level="4.2.1" data-path="interpglobal.html"><a href="interpglobal.html#vantagens-e-desvantagens-1"><i class="fa fa-check"></i><b>4.2.1</b> Vantagens e Desvantagens</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="interpglobal.html"><a href="interpglobal.html#efeitos-acumulados-locais-accumulated-local-effects---ale"><i class="fa fa-check"></i><b>4.3</b> Efeitos Acumulados Locais (<em>Accumulated Local Effects</em>) - ALE</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interplocal.html"><a href="interplocal.html"><i class="fa fa-check"></i><b>5</b> Interpretabilidade Local</a></li>
<li class="chapter" data-level="6" data-path="conclusao.html"><a href="conclusao.html"><i class="fa fa-check"></i><b>6</b> Conclusões e Discussões</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interprete o seu modelo caixa-preta!</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="caracteristicas" class="section level1">
<h1><span class="header-section-number">Capítulo 3</span> Características dos métodos de interpretabilidade</h1>
<p>Uma possível abordagem para interpretabilidade de modelos de aprendizado de máquina que não são entendidos diretamente por suas fórmulas, os chamados modelos caixa preta, é usar métodos modelo-agnósticos <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-modelagnostic">2016</a>)</span> para interpretabilidade. Essa abordagem consiste em extrair explicações do modelo ajustado, considerando os resultados da predição/classificação para fazer análises. As análises se dão pela modificação de variáveis de entradas e observação de como o modelo se altera em cada uma das modificações realizadas.</p>
<p>Antes de abordar os métodos estudados nesse trabalho, traremos a seguir três atributos que caracterizam esses métodos: Flexibilidade do Modelo, Flexibilidade de Explicação e Flexibilidade de Representação.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Flexibilidade do Modelo</strong></p>
<p>Separar a etapa de interpretabilidade da etapa de ajuste do modelo permite que o modelo seja o mais flexível possível, pois possibilita o uso de qualquer abordagem de modelagem. Se a abordagem do problema for Florestas Aleatórias ou se for SVMs, por exemplo, o método de interpretação utilizado será o mesmo. Esse ponto leva à discussão o  interpretabilidade  complexidade do modelo, uma vez que abordamos modelos mais ou menos complexos com os mesmo métodos de interpretabilidade.</p></li>
<li><p><strong>Flexibilidade de Explicação</strong></p>
<p>Diferentes tipos de problemas e necessidades levam à diferentes tipos de explicações. Em alguns casos, os usuários podem se preocupar em entender como os resultados positivos impactam em uma determinada previsão. Por exemplo, qual parte de um imagem é mais responsável pela previsão (exemplo do cavalo e do automóvel), enquanto em outros casos em que o impacto negativo pode ser o interesse, por exemplo, na depuração de um classificador de contratação (exemplo do Classificador Sexista de contratação). Temos também os casos em que a necessidade de informação pode ser também contrafactual, por exemplo, como o modelo se comportaria se certas características tivessem valores diferentes.</p>
<p>Usuários diferentes também podem lidar com diferentes tipos de explicações. Um leigo pode ser capaz de entender uma Árvore de Decisão com um número um pouco maior de regras, enquanto um modelo linear é mais intuitivo para um usuário acostumado com modelos estatísticos. No entanto, a maioria dos modelos interpretáveis são restritos nas possíveis explicações, seja por um conjunto de regras ou por gráficos. Assim, mantendo o modelo separado das explicações, é possível adaptar a explicação às necessidades de informações, mantendo o modelo fixo, ou seja, independente do modelo abordado, ele pode ser explicado de diferentes maneira e diferentes graus de interpretabilidade.</p></li>
<li><p><strong>Flexibilidade de Representação</strong></p>
<p>A característica de Flexibilidade na Representação está relacionada a gerar explicações usando recursos diferentes, de acordo com o modelo que está sendo explicado. Por exemplo, para um classificador de texto que usa vetores de incorporação de palavras abstratas, pode ser preferível usar a presença de palavras individuais para a explicação <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-modelagnostic">2016</a>)</span>.</p></li>
</ol>
<p>Com as características essenciais aos métodos de interpretabilidade abordadas, estudamos alguns métodos utilizados, suas definições e como eles ajudam a entender a relação do predito com as variáveis explicativas. Nas próximas seções descrevemos alguns métodos de interpretabilidade que podem ser aplicados a qualquer modelo de predição, abordando uma perspectiva de interpretabilidade Global e, posteriormente, Local.</p>

</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-modelagnostic">
<p>Ribeiro, M., S. Singh, and C. Guestrin. 2016. “Model-Agnostic Interpretability of Machine Learning.” <em>arXiv Preprint</em> arXiv:1606.05386.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interpglobal.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["interpretabilidade.pdf", "interpretabilidade.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
